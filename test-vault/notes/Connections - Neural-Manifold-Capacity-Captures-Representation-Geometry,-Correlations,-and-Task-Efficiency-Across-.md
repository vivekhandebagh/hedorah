---
title: "Connections - Neural-Manifold-Capacity-Captures-Representation-Geometry,-Correlations,-and-Task-Efficiency-Across-"
created: 2025-11-24T22:08:45.143598
tags:
  - connections
  - research-graph
  - ai-interpretability
source_paper: "Neural Manifold Capacity Captures Representation Geometry, Correlations, and Task-Efficiency Across Species and Behaviors"
---

# Connections - Neural-Manifold-Capacity-Captures-Representation-Geometry,-Correlations,-and-Task-Efficiency-Across-

**Source:** [[Neural Manifold Capacity Captures Representation Geometry, Correlations, and Task-Efficiency Across Species and Behaviors]]

## [[Neural Population Doctrine]]
**Related to:**
- [[Distributed neural coding]]
- [[Population vector algorithms]]
- [[High-dimensional neural dynamics]]

GCMC provides quantitative tools for the population-level analysis that the neural population doctrine requires, moving beyond single-neuron perspectives

## [[Manifold Learning]]
**Related to:**
- [[Dimensionality reduction]]
- [[Nonlinear dynamics]]
- [[Geometric deep learning]]

GCMC extends manifold learning by incorporating correlation structure and linking geometry to computational efficiency, rather than just dimensionality

## [[Information Theory in Neuroscience]]
**Related to:**
- [[Mutual information]]
- [[Channel capacity]]
- [[Efficient coding]]

GCMC provides a geometric interpretation of information-theoretic principles, connecting abstract information measures to concrete neural geometry

## [[Statistical Mechanics of Neural Networks]]
**Related to:**
- [[Replica theory]]
- [[Random matrix theory]]
- [[Critical phenomena]]

GCMC applies statistical physics methods to understand emergent properties of neural populations, similar to phase transitions in physical systems
